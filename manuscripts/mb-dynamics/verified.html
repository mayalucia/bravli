<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Network Dynamics of the /Drosophila/ Mushroom Body: Regime Classification, Neuromodulation, Stochasticity, and Model Invariance</title>
<style>

/* === Reset & Base === */
*, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

body {
  font-family: Georgia, 'Times New Roman', 'Noto Serif', serif;
  font-size: 17px;
  line-height: 1.7;
  color: #2d2d2d;
  background: #fafaf8;
  max-width: 52em;
  margin: 0 auto;
  padding: 2em 2em 4em;
}

/* === Header === */
header {
  border-bottom: 1px solid #ddd;
  padding-bottom: 1.5em;
  margin-bottom: 2em;
}

.paper-title {
  font-size: 1.6em;
  font-weight: 700;
  line-height: 1.3;
  color: #1a1a1a;
  margin-bottom: 0.3em;
}

.paper-meta {
  color: #666;
  font-size: 0.95em;
  margin-bottom: 1.2em;
}
.paper-meta .author { margin-right: 1.5em; }

.verification-banner {
  display: flex;
  gap: 1.5em;
  padding: 0.8em 1.2em;
  background: #f0f0ee;
  border-radius: 4px;
  border-left: 4px solid #2d8a4e;
}

.banner-item {
  display: flex;
  flex-direction: column;
  align-items: center;
}
.banner-number {
  font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
  font-size: 1.3em;
  font-weight: 700;
  color: #2d2d2d;
}
.banner-item.pass .banner-number { color: #2d8a4e; }
.banner-item.fail .banner-number { color: #c94040; }
.banner-label {
  font-size: 0.75em;
  color: #888;
  text-transform: uppercase;
  letter-spacing: 0.05em;
}

/* === Navigation === */
nav.toc {
  border-bottom: 1px solid #eee;
  padding-bottom: 1em;
  margin-bottom: 2.5em;
}
.toc-title {
  font-size: 0.8em;
  text-transform: uppercase;
  letter-spacing: 0.1em;
  color: #999;
  margin-bottom: 0.5em;
}
nav.toc a {
  display: block;
  color: #555;
  text-decoration: none;
  font-size: 0.9em;
  padding: 0.15em 0;
}
nav.toc a:hover { color: #1a1a1a; }
nav.toc a.nav-l2 { padding-left: 1.5em; font-size: 0.85em; }

/* === Body === */
main h2 {
  font-size: 1.35em;
  margin-top: 2.5em;
  margin-bottom: 0.5em;
  color: #1a1a1a;
  border-bottom: 1px solid #eee;
  padding-bottom: 0.2em;
}
main h3 {
  font-size: 1.15em;
  margin-top: 1.8em;
  margin-bottom: 0.4em;
  color: #333;
}
main h4 {
  font-size: 1.0em;
  margin-top: 1.4em;
  margin-bottom: 0.3em;
  color: #444;
  font-style: italic;
}

main p {
  margin-bottom: 1em;
  text-align: justify;
  hyphens: auto;
}

/* === Math & Code === */
code.math {
  font-family: 'SF Mono', 'Fira Code', monospace;
  font-size: 0.88em;
  color: #555;
  background: none;
  padding: 0;
}
code.latex {
  font-family: 'SF Mono', 'Fira Code', monospace;
  font-size: 0.85em;
  color: #555;
  display: block;
  white-space: pre-wrap;
  padding: 0.5em 1em;
}
div.equation {
  margin: 1em 0;
  padding: 0.5em 0;
  text-align: center;
  background: #f8f8f6;
  border-radius: 3px;
}
code {
  font-family: 'SF Mono', 'Fira Code', 'Consolas', monospace;
  font-size: 0.88em;
  background: #f0f0ee;
  padding: 0.1em 0.3em;
  border-radius: 2px;
}

/* === Tables === */
table.booktabs {
  border-collapse: collapse;
  margin: 1.2em auto;
  font-size: 0.92em;
}
table.booktabs thead {
  border-top: 2px solid #333;
  border-bottom: 1px solid #999;
}
table.booktabs tbody {
  border-bottom: 2px solid #333;
}
table.booktabs th, table.booktabs td {
  padding: 0.4em 1em;
  text-align: left;
}
table.booktabs th {
  font-weight: 600;
  color: #333;
}

/* === Lists === */
ul, ol {
  margin: 0.5em 0 1em 1.5em;
}
li {
  margin-bottom: 0.3em;
}

/* === Citations === */
a.citation {
  color: #2d8a4e;
  text-decoration: none;
  font-size: 0.9em;
}
a.citation:hover { text-decoration: underline; }

/* === Verification Badges === */
.badge-group {
  white-space: nowrap;
}
.badge {
  display: inline-block;
  font-family: 'SF Mono', 'Fira Code', monospace;
  font-size: 0.72em;
  padding: 0.15em 0.5em;
  border-radius: 3px;
  cursor: pointer;
  vertical-align: middle;
  margin-left: 0.3em;
  transition: background 0.15s;
  user-select: none;
}
.badge.pass {
  background: #e6f4ea;
  color: #2d8a4e;
  border: 1px solid #b7dfc3;
}
.badge.pass:hover { background: #d0ebd8; }
.badge.fail {
  background: #fde8e8;
  color: #c94040;
  border: 1px solid #f0bebe;
}
.badge.fail:hover { background: #f9d4d4; }
.badge.missing {
  background: #f0f0ee;
  color: #999;
  border: 1px solid #ddd;
}
.badge.skip {
  background: #f5f0e0;
  color: #997a00;
  border: 1px solid #e0d5a0;
}

.badge-detail {
  display: none;
  margin: 0.5em 0 1em;
  padding: 0.8em 1em;
  background: #f8f8f6;
  border: 1px solid #e5e5e0;
  border-radius: 4px;
  font-size: 0.88em;
}
.claim-text {
  color: #555;
  font-style: italic;
  margin-bottom: 0.6em;
  font-size: 0.92em;
}
.test-item {
  margin-bottom: 0.8em;
}
.test-name {
  display: block;
  font-weight: 600;
  color: #2d8a4e;
  margin-bottom: 0.2em;
  background: none;
}
.test-source {
  font-family: 'SF Mono', 'Fira Code', monospace;
  font-size: 0.82em;
  background: #f0f0ee;
  padding: 0.5em 0.8em;
  border-radius: 3px;
  overflow-x: auto;
  margin: 0.3em 0;
  line-height: 1.4;
}
.test-cmd {
  display: block;
  font-size: 0.8em;
  color: #888;
  background: none;
}

/* === References === */
.references {
  margin-top: 3em;
  border-top: 1px solid #ddd;
  padding-top: 1em;
}
.ref-entry {
  font-size: 0.9em;
  margin-bottom: 0.5em;
  padding-left: 1em;
  text-indent: -1em;
  color: #444;
}

/* === Footer === */
footer {
  margin-top: 3em;
  padding-top: 1em;
  border-top: 2px solid #2d8a4e;
  font-size: 0.85em;
  color: #666;
}
.verify-prompt {
  background: #f0f0ee;
  padding: 0.8em 1em;
  border-radius: 4px;
  margin-bottom: 0.5em;
}
.verify-prompt code {
  font-size: 0.85em;
  display: block;
  margin-top: 0.3em;
}
.build-info {
  font-size: 0.8em;
  color: #999;
}

/* === Print === */
@media print {
  body { max-width: none; padding: 0; font-size: 11pt; }
  .badge { border: 1px solid #999; }
  .badge-detail { display: none !important; }
  nav.toc { display: none; }
  footer { border-top: 1px solid #999; }
  .verification-banner { border-left-color: #999; }
}

</style>
</head>
<body>

<header>
  <h1 class="paper-title">Network Dynamics of the <em>Drosophila</em> Mushroom Body: Regime Classification, Neuromodulation, Stochasticity, and Model Invariance</h1>
  <div class="paper-meta">
    <span class="author">Darshan Muchu</span>
    <span class="date">2026</span>
  </div>
  <div class="verification-banner">
    <div class="banner-item">
      <span class="banner-number">29</span>
      <span class="banner-label">claims</span>
    </div>
    <div class="banner-item pass">
      <span class="banner-number">29</span>
      <span class="banner-label">verified &#10003;</span>
    </div>
    <div class="banner-item fail" style="display:none">
      <span class="banner-number">0</span>
      <span class="banner-label">failed &#10007;</span>
    </div>
    <div class="banner-item neutral">
      <span class="banner-number">293</span>
      <span class="banner-label">tests pass</span>
    </div>
    <div class="banner-item neutral">
      <span class="banner-number">57.92s</span>
      <span class="banner-label">runtime</span>
    </div>
  </div>
</header>

<nav class="toc">
  <div class="toc-title">Contents</div>
  <a class="nav-l1" href="#introduction">Introduction</a>
<a class="nav-l1" href="#methods">Methods</a>
<a class="nav-l2" href="#circuit-extraction">Circuit Extraction</a>
<a class="nav-l2" href="#simulation-engines">Simulation Engines</a>
<a class="nav-l2" href="#neuromodulatory-state-model">Neuromodulatory State Model</a>
<a class="nav-l2" href="#brunel-regime-classification">Brunel Regime Classification</a>
<a class="nav-l2" href="#stochastic-resonance-protocol">Stochastic Resonance Protocol</a>
<a class="nav-l2" href="#lif-adex-comparison-protocol">LIF--AdEx Comparison Protocol</a>
<a class="nav-l1" href="#results">Results</a>
<a class="nav-l2" href="#the-flywire-mushroom-body-operates-in-the-balanced-state">The FlyWire Mushroom Body Operates in the Balanced State</a>
<a class="nav-l2" href="#neuromodulation-reconfigures-behavioural-output-without-rewiring">Neuromodulation Reconfigures Behavioural Output Without Rewiring</a>
<a class="nav-l2" href="#stochastic-synaptic-transmission-serves-computation">Stochastic Synaptic Transmission Serves Computation</a>
<a class="nav-l2" href="#topology-dominates-lif-and-adex-agree-when-adaptation-is-weak">Topology Dominates: LIF and AdEx Agree When Adaptation Is Weak</a>
<a class="nav-l1" href="#discussion">Discussion</a>
<a class="nav-l2" href="#synthesis-four-views-of-one-circuit">Synthesis: Four Views of One Circuit</a>
<a class="nav-l2" href="#limitations">Limitations</a>
<a class="nav-l2" href="#future-directions">Future Directions</a>
<a class="nav-l2" href="#conclusion">Conclusion</a>
</nav>

<main>
<h2 id="introduction">Introduction</h2>
<p>The completion of the <em>Drosophila</em> whole-brain connectome by the FlyWire
consortium [<a class<code>"citation" href</code>"#ref-dorkenwald2024">dorkenwald2024</a>] represents a watershed moment in
neuroscience: 139,255 neurons, approximately 50 million synapses, and
8,453 cell types, reconstructed at synaptic resolution from a single
female fly. For the first time, we have a complete parts list and
wiring diagram of an adult brain. But a parts list is not a theory.
The central challenge now is to understand how dynamics emerge from
structure &mdash; how the static connectome gives rise to the temporal
patterns of activity that underlie computation, learning, and
behaviour.</p>
<p>The mushroom body (MB) is an ideal test case for this enterprise. It
is the primary locus of associative olfactory learning in <em>Drosophila</em>
[<a class<code>"citation" href</code>"#ref-aso2014">aso2014</a>], its architecture is well understood (approximately
2,000 Kenyon cells receiving convergent input from ~150 projection
neurons, with output modulated by ~30 mushroom body output neurons and
~130 dopaminergic neurons), and its behavioural relevance is directly
measurable. The MB's compartmental organisation [<a class<code>"citation" href</code>"#ref-aso2014">aso2014</a>] &mdash;
with distinct dopaminergic and output neuron types tiling the KC axon
lobes &mdash; provides a natural framework for understanding how
neuromodulation sculpts circuit output.</p>
<p>We address four questions, each probing a different aspect of the
structure&ndash;dynamics relationship:</p>
<ul><li><strong>What dynamical regime does the MB operate in?</strong> The Brunel (2000)</li>
</ul>   framework [<a class<code>"citation" href</code>"#ref-brunel2000">brunel2000</a>] classifies recurrent networks into four
   regimes based on the balance between excitation and inhibition (<code class="math">g</code>)
   and external drive (<code class="math">η</code>). We ask where the FlyWire MB falls in this
   phase diagram.
<ul><li><strong>Can the same connectome produce opposite behaviours?</strong> Marder's</li>
</ul>   principle [<a class<code>"citation" href</code>"#ref-marder2002">marder2002</a>, <a class<code>"citation" href</code>"#ref-marder2012">marder2012</a>] holds that neuromodulation
   reconfigures circuit function without rewiring. We test whether
   compartment-specific gain modulation &mdash; mimicking the effects of
   different aminergic and peptidergic states &mdash; can switch the MB's
   behavioural output between approach and avoidance.
<ul><li><strong>How does synaptic noise affect circuit function?</strong> Central</li>
</ul>   synapses are unreliable, with release probabilities of $p \approx
   0.1<code class<code>"math">&ndash;</code>0.5$ [<a class</code>"citation" href="#ref-allen1994">allen1994</a>]. Rather than treating this as a bug,
   we ask whether stochastic transmission serves computational purposes
   &mdash; specifically, whether stochastic resonance
   [<a class<code>"citation" href</code>"#ref-gammaitoni1998">gammaitoni1998</a>] enhances signal detection in the MB circuit.
<ul><li><strong>Does the single-neuron model matter?</strong> Zhang et al.</li>
</ul>   [<a class<code>"citation" href</code>"#ref-zhang2024">zhang2024</a>] demonstrated that connectome-constrained models of
   the fly visual system produce accurate predictions regardless of
   neuron model complexity. We test whether this topology-dominates
   hypothesis extends to the MB by comparing LIF and AdEx
   [<a class<code>"citation" href</code>"#ref-brette2005">brette2005</a>] neuron models on the same extracted circuit.
<p>Our approach is deliberately minimal. We use current-injection
integrate-and-fire models (LIF and AdEx), not conductance-based
neurons. We use extracted synaptic weights, not fitted parameters. The
goal is not biophysical realism but <em>computational insight</em>: what can
the connectome alone tell us, and where does it fall short?</p>
<h2 id="methods">Methods</h2>
<h3 id="circuit-extraction">Circuit Extraction</h3>
<p>We extract the MB microcircuit from the FlyWire connectome using the
<code>bravli</code> Python toolkit developed for this study. Starting from
anatomical neuron classifications, we identify five cell populations:</p>
<ul><li><strong>Projection neurons (PNs)</strong>: ~150 neurons carrying olfactory input</li>
</ul>  from the antennal lobe.
<ul><li><strong>Kenyon cells (KCs)</strong>: ~5,200 principal neurons forming the MB's</li>
</ul>  sparse coding layer, subdivided by lobe (gamma, alpha/beta,
  alpha'/beta').
<ul><li><strong>Mushroom body output neurons (MBONs)</strong>: ~30 neurons whose combined</li>
</ul>  activity drives approach or avoidance behaviour.
<ul><li><strong>Dopaminergic neurons (DANs)</strong>: ~130 neurons (PAM and PPL1 clusters)</li>
</ul>  providing reward and punishment signals.
<ul><li><strong>APL (anterior paired lateral)</strong>: A single giant GABAergic neuron</li>
</ul>  providing global inhibition to KCs.
<p>Synaptic connectivity is extracted from the FlyWire synapse table,
retaining synapse counts as weight proxies. The resulting circuit
contains approximately 6,300 neurons and 50,000 synapses.</p>
<h3 id="simulation-engines">Simulation Engines</h3>
<h4 id="leaky-integrate-and-fire-lif">Leaky Integrate-and-Fire (LIF)</h4>
<p>The membrane potential of neuron <code class="math">i</code> evolves as:
<div class<code>"equation"><code class</code>"latex">\tau_m \frac{dV_i}{dt} = -(V_i - V_{\text{rest}}) + g_i(t)</code></div>
where <code class<code>"math">τ_m</code> is the membrane time constant, <code class</code>"math">V_{rest} = 0</code> mV
is the resting potential, and <code class="math">g_i(t)</code> is the total synaptic input.
When <code class<code>"math">V_i</code> crosses threshold <code class</code>"math">V_theta = 20</code> mV, a spike is emitted,
the potential is reset to <code class<code>"math">V_{reset} </code> 0</code> mV, and the neuron
enters an absolute refractory period of <code class<code>"math">τ_ref </code> 2</code> ms.</p>
<p>Synaptic input is delivered with an exponential filter:
<div class<code>"equation"><code class</code>"latex">\tau_s \frac{dg_i}{dt} = -g_i + \tau_m \sum_j w_{ji} \sum_k \delta(t - t_j^k - d_{ji})</code></div>
where <code class<code>"math">w_{ji}</code> is the synaptic weight from neuron <code class</code>"math">j</code> to <code class="math">i</code>,
<code class<code>"math">t_j^k</code> is the <code class</code>"math">k</code>-th spike time of neuron <code class<code>"math">j</code>, <code class</code>"math">d_{ji}</code> is the
synaptic delay (1.5 ms throughout), and <code class<code>"math">τ_s </code> 0.5</code> ms is the
synaptic time constant. The factor <code class="math">τ_m / τ_s</code> ensures that the
effective weight matches the delta-synapse convention of Brunel
[<a class<code>"citation" href</code>"#ref-brunel2000">brunel2000</a>].</p>
<p>Cell-type-specific parameters follow from known biophysics: KCs have
short membrane time constants (<code class<code>"math">τ_m </code> 5</code> ms) reflecting their
compact morphology, while MBONs (<code class<code>"math">τ_m </code> 15</code> ms) and DANs
(<code class<code>"math">τ_m </code> 20</code> ms) are larger and slower.</p>
<h4 id="adaptive-exponential-integrate-and-fire-adex">Adaptive Exponential Integrate-and-Fire (AdEx)</h4>
<p>The AdEx model [<a class<code>"citation" href</code>"#ref-brette2005">brette2005</a>] extends LIF with exponential spike
initiation and a slow adaptation current:
<div class<code>"equation"><code class</code>"latex">\tau_m \frac{dV_i}{dt} &amp;= -(V_i - V_{\text{rest}}) + \Delta_T \exp\!\left(\frac{V_i - V_T}{\Delta_T}\right) + g_i(t) - w_i \\
\tau_w \frac{dw_i}{dt} &amp;= a(V_i - V_{\text{rest}}) - w_i</code></div>
where <code class<code>"math">Δ_T </code> 2</code> mV is the exponential slope factor, <code class="math">V_T</code> is the
effective threshold, <code class="math">a</code> is the subthreshold adaptation conductance,
and <code class="math">w_i</code> is the adaptation current. At spike time, $w_i \leftarrow
w_i + b<code class="math">, where </code>b$ controls spike-frequency adaptation strength.</p>
<p>We use four biophysically motivated presets:
<ul><li><strong>Regular spiking</strong>: <code class<code>"math">a </code> 0</code>, <code class<code>"math">b </code> 0.5</code> mV, <code class<code>"math">τ_w </code> 100</code> ms</li>
<li><strong>Adapting</strong>: <code class<code>"math">a </code> 0.1</code> nS, <code class<code>"math">b </code> 2.0</code> mV, <code class<code>"math">τ_w </code> 300</code> ms</li>
<li><strong>Bursting</strong>: <code class<code>"math">a </code> 0</code>, <code class<code>"math">b </code> 5.0</code> mV, <code class<code>"math">τ_w </code> 50</code> ms</li>
<li><strong>Fast spiking</strong>: <code class<code>"math">a </code> 0</code>, <code class<code>"math">b </code> 0</code>, <code class<code>"math">τ_w </code> 100</code> ms (equivalent to exponential LIF)</li></ul> <span class="badge-group"><span class="badge pass" onclick="toggle('r4_c5')">&#10003; 2/2</span><div class="badge-detail" id="r4_c5"><div class="claim-text">Four biophysically motivated AdEx presets defined</div><div class="test-item"><code class="test-name">test_adex.py::test_presets_exist</code><pre class="test-source">    def test_presets_exist(self):
        assert "regular_spiking" in ADEX_PRESETS
        assert "adapting" in ADEX_PRESETS
        assert "bursting" in ADEX_PRESETS
        assert "fast_spiking" in ADEX_PRESETS
</pre><code class="test-cmd">pytest tests/test_adex.py::test_presets_exist -v</code></div>
<div class="test-item"><code class="test-name">test_adex.py::test_preset_types</code><pre class="test-source">    def test_preset_types(self):
        for name, params in ADEX_PRESETS.items():
            assert isinstance(params, AdExParams)
            assert params.delta_t &gt; 0
            assert params.tau_w &gt; 0


# ---------------------------------------------------------------------------</pre><code class="test-cmd">pytest tests/test_adex.py::test_preset_types -v</code></div></div></span></p>
<h4 id="stochastic-synaptic-transmission">Stochastic Synaptic Transmission</h4>
<p>Two noise mechanisms are implemented:</p>
<ul><li><strong>Release failure</strong>: Each spike arriving at a synapse is transmitted</li>
</ul>   with probability <code class<code>"math">p_{rel}</code> (Bernoulli trial). At <code class</code>"math">p_{rel} = 1</code>,
   transmission is deterministic. At biologically realistic values
   (<code class<code>"math">p_{rel} ≈ 0.1</code>&ndash;<code class</code>"math">0.5</code>), most spikes fail to elicit
   postsynaptic responses [<a class<code>"citation" href</code>"#ref-allen1994">allen1994</a>].
<ul><li><strong>Intrinsic noise</strong>: Gaussian current noise <code class="math">xi_i(t)</code> is added to</li>
</ul>   the membrane equation, scaled as <code class="math">σ sqrt{dt}</code> to ensure
   proper Wiener process scaling. This captures channel noise, thermal
   fluctuations, and background synaptic bombardment
   [<a class<code>"citation" href</code>"#ref-faisal2008">faisal2008</a>].
<h3 id="neuromodulatory-state-model">Neuromodulatory State Model</h3>
<p>Following [<a class<code>"citation" href</code>"#ref-marder2002">marder2002</a>], we model neuromodulation as
compartment-specific multiplicative gain modulation of synaptic
weights:
<div class<code>"equation"><code class</code>"latex">w_{\text{eff}} = w_{\text{base}} \times m_c</code></div>
where <code class<code>"math">m_c</code> is the modulatory gain for compartment <code class</code>"math">c</code>. The MB's 15
compartments [<a class<code>"citation" href</code>"#ref-aso2014">aso2014</a>] each receive distinct dopaminergic
innervation, and the gain factors <code class="math">m_c</code> reflect the known valence
organisation:</p>
<table class="booktabs">
<thead><tr><th>State</th><th>Compartment modulation</th><th>Behavioural prediction</th></tr></thead><tbody>
<tr><td>Naive</td><td>All <code class<code>"math">m_c </code> 1.0</code></td><td>Neutral</td></tr>
<tr><td>Appetitive</td><td>Appetitive <code class<code>"math">m_c </code> 1.3</code>&ndash;<code class<code>"math">1.5</code>; aversive <code class</code>"math">m_c = 0.6</code></td><td>Approach</td></tr>
<tr><td>Aversive</td><td>Aversive <code class<code>"math">m_c </code> 1.5</code>; appetitive <code class<code>"math">m_c </code> 0.6</code></td><td>Avoidance</td></tr>
<tr><td>Aroused</td><td>All <code class<code>"math">m_c </code> 1.3</code></td><td>Enhanced response</td></tr>
<tr><td>Quiescent</td><td>All <code class<code>"math">m_c </code> 0.5</code></td><td>Suppressed response</td></tr>
</tbody></table> <span class="badge-group"><span class="badge pass" onclick="toggle('r1_c8')">&#10003; 1/1</span><div class="badge-detail" id="r1_c8"><div class="claim-text">Below-threshold drive produces quiescent state</div><div class="test-item"><code class="test-name">test_brunel.py::test_quiescent_regime</code><pre class="test-source">    def test_quiescent_regime(self):
        """Below-threshold drive should produce quiescent state."""
        from bravli.explore.brunel_network import (
            build_brunel_network, build_brunel_stimulus, classify_regime,
        )
        circuit, params = build_brunel_network(
            n_excitatory=200, g=8.0, eta=0.5, seed=42
        )</pre><code class="test-cmd">pytest tests/test_brunel.py::test_quiescent_regime -v</code></div></div></span>
<p>Behavioural output is quantified via a valence score:
<div class<code>"equation"><code class</code>"latex">V = \sum_{i \in \text{appetitive}} r_i^{\text{MBON}} - \sum_{j \in \text{aversive}} r_j^{\text{MBON}}</code></div>
where <code class<code>"math">V &gt; 0</code> predicts approach and <code class</code>"math">V &lt; 0</code> predicts avoidance.</p>
<h3 id="brunel-regime-classification">Brunel Regime Classification</h3>
<p>The Brunel [<a class<code>"citation" href</code>"#ref-brunel2000">brunel2000</a>] framework classifies network dynamics
along two axes:</p>
<ul><li><strong>Irregularity</strong>: coefficient of variation of interspike intervals.</li>
</ul>  <code class<code>"math">CV &gt; 0.5</code> indicates irregular firing; <code class</code>"math">CV &lt; 0.5</code>
  indicates regular firing.
<ul><li><strong>Synchrony</strong>: a synchrony index based on variance of the population</li>
</ul>  rate relative to single-neuron variance. Synchrony <code class="math">&gt; 10</code> indicates
  synchronous firing.
<p>The four regimes are:
<ul><li><strong>SR</strong> (Synchronous Regular): low CV, high synchrony</li>
<li><strong>SI</strong> (Synchronous Irregular): high CV, high synchrony &mdash; pathological</li>
<li><strong>AR</strong> (Asynchronous Regular): low CV, low synchrony &mdash; clock-like</li>
<li><strong>AI</strong> (Asynchronous Irregular): high CV, low synchrony &mdash; the balanced state</li></ul></p>
<p>For the Brunel sweep, we construct random networks of <code class<code>"math">N </code> 10{,}000</code>
neurons (80% excitatory, 20% inhibitory) with connection probability
<code class<code>"math">ε </code> 0.1</code> and scan the parameter space $g \in \{3, 4, 4.5, 5,
6\}<code class="math"> and </code>\eta \in \{0.9, 1.5, 2, 3, 4\}$. <span class="badge-group"><span class="badge pass" onclick="toggle('r1_c6')">&#10003; 2/2</span><div class="badge-detail" id="r1_c6"><div class="claim-text">Network construction: 80% excitatory, 20% inhibitory neurons</div><div class="test-item"><code class="test-name">test_brunel.py::test_build_network</code><pre class="test-source">    def test_build_network(self, small_brunel):
        circuit, params = small_brunel
        assert circuit.n_neurons == 250  # 200 E + 50 I
        assert circuit.n_synapses &gt; 0
        assert params["n_excitatory"] == 200
        assert params["n_inhibitory"] == 50
</pre><code class="test-cmd">pytest tests/test_brunel.py::test_build_network -v</code></div>
<div class="test-item"><code class="test-name">test_brunel.py::test_ei_ratio</code><pre class="test-source">    def test_ei_ratio(self, small_brunel):
        circuit, params = small_brunel
        n_e = params["n_excitatory"]
        n_i = params["n_inhibitory"]
        assert n_i / n_e == pytest.approx(0.25)
</pre><code class="test-cmd">pytest tests/test_brunel.py::test_ei_ratio -v</code></div></div></span></p>
<h3 id="stochastic-resonance-protocol">Stochastic Resonance Protocol</h3>
<p>A subthreshold periodic signal (<code class<code>"math">f </code> 5</code> Hz, amplitude 3 mV below
threshold) is injected into a test circuit alongside varying levels of
intrinsic noise (<code class="math">σ in \{0, 0.5, 1, 2, 3, 5, 7, 10, 15, 20\}</code>).
The signal-to-noise ratio (SNR) is computed from the power spectrum of
the population firing rate:
<div class<code>"equation"><code class</code>"latex">\text{SNR} = \frac{P(f_{\text{signal}})}{P_{\text{noise}}}</code></div>
where <code class="math">P(f_{signal})</code> is the spectral power at the signal
frequency and <code class="math">P_{noise}</code> is the mean power at surrounding
frequencies. Stochastic resonance manifests as a peak in SNR at
intermediate noise levels.</p>
<h3 id="lif-adex-comparison-protocol">LIF--AdEx Comparison Protocol</h3>
<p>We simulate the same MB circuit with both LIF and AdEx engines,
matching all parameters except the adaptation current. Three metrics
quantify agreement:</p>
<ul><li><strong>Rate correlation</strong>: Pearson correlation of per-neuron firing rates</li>
</ul>   between LIF and AdEx simulations.
<ul><li><strong>Temporal correlation</strong>: Correlation of population rate time series</li>
</ul>   (5 ms bins).
<ul><li><strong>Mean relative difference</strong>: <code class="math">⟨ 2|r_{LIF} - r_{AdEx}| / (r_{LIF} + r_{AdEx}) ⟩</code> averaged over active neurons.</li></ul>
<p>Interpretation thresholds: rate correlation <code class="math">&gt; 0.9</code> indicates topology
dominates; <code class="math">&lt; 0.5</code> indicates the neuron model is essential.</p>
<h2 id="results">Results</h2>
<h3 id="the-flywire-mushroom-body-operates-in-the-balanced-state">The FlyWire Mushroom Body Operates in the Balanced State</h3>
<p>To classify the MB's dynamical regime, we first establish the Brunel
phase diagram as a reference. The <code class="math">(g, η)</code> parameter sweep on random networks recovers all four regimes. The classical four
regimes are recovered, though the AI/SI boundary shifts to higher <code class="math">g</code>
compared to the canonical delta-synapse result. This is a direct
consequence of our exponential synaptic filter (<code class<code>"math">τ_s </code> 0.5</code> ms):
finite-duration postsynaptic currents smooth out membrane voltage
fluctuations, suppressing the coefficient of variation. Even at $g =
8<code class<code>"math">, the CV reaches only </code>\sim 0.25<code class</code>"math"> rather than the </code>\sim 0.8<code class="math">&ndash;</code>1.0$
expected with delta synapses. The effective weight scaling $J_{\text{eff}}
= J \times \tau_m / \tau_s$ compensates for the reduced peak current
but cannot restore the shot-noise statistics that drive irregular
firing. <span class="badge-group"><span class="badge pass" onclick="toggle('r1_c1')">&#10003; 2/2</span><div class="badge-detail" id="r1_c1"><div class="claim-text">Brunel phase diagram recovers four regimes (SR, SI, AR, AI)</div><div class="test-item"><code class="test-name">test_brunel.py::test_classification_keys</code><pre class="test-source">    def test_classification_keys(self, small_brunel):
        from bravli.explore.brunel_network import build_brunel_stimulus, classify_regime
        circuit, params = small_brunel
        stim = build_brunel_stimulus(circuit, params, duration_ms=200.0, seed=42)
        result = simulate(circuit, duration=200.0, dt=0.1, stimulus=stim, seed=42)
        c = classify_regime(result)
        assert "regime" in c
        assert "cv_isi" in c</pre><code class="test-cmd">pytest tests/test_brunel.py::test_classification_keys -v</code></div>
<div class="test-item"><code class="test-name">test_brunel.py::test_sweep_has_all_points</code><pre class="test-source">    def test_sweep_has_all_points(self):
        from bravli.explore.brunel_network import brunel_phase_sweep
        df = brunel_phase_sweep(
            g_values=[3.0, 6.0],
            eta_values=[1.0, 2.0, 3.0],
            n_excitatory=200,
            duration_ms=200.0,
            seed=42,</pre><code class="test-cmd">pytest tests/test_brunel.py::test_sweep_has_all_points -v</code></div></div> <span class="badge pass" onclick="toggle('r1_c2')">&#10003; 1/1</span><div class="badge-detail" id="r1_c2"><div class="claim-text">AI/SI boundary shifts to higher g with exponential synaptic filtering</div><div class="test-item"><code class="test-name">test_brunel.py::test_cv_increases_with_g</code><pre class="test-source">    def test_cv_increases_with_g(self):
        """Stronger inhibition should increase CV (more irregular firing)."""
        from bravli.explore.brunel_network import (
            build_brunel_network, build_brunel_stimulus, classify_regime,
        )
        cvs = []
        for g in [3.0, 6.0]:
            circuit, params = build_brunel_network(</pre><code class="test-cmd">pytest tests/test_brunel.py::test_cv_increases_with_g -v</code></div></div> <span class="badge pass" onclick="toggle('r1_c3')">&#10003; 1/1</span><div class="badge-detail" id="r1_c3"><div class="claim-text">CV suppressed by exponential filter (CV ~0.25 at g=8 vs ~0.8 with delta synapses)</div><div class="test-item"><code class="test-name">test_brunel.py::test_cv_increases_with_g</code><pre class="test-source">    def test_cv_increases_with_g(self):
        """Stronger inhibition should increase CV (more irregular firing)."""
        from bravli.explore.brunel_network import (
            build_brunel_network, build_brunel_stimulus, classify_regime,
        )
        cvs = []
        for g in [3.0, 6.0]:
            circuit, params = build_brunel_network(</pre><code class="test-cmd">pytest tests/test_brunel.py::test_cv_increases_with_g -v</code></div></div> <span class="badge pass" onclick="toggle('r1_c4')">&#10003; 2/2</span><div class="badge-detail" id="r1_c4"><div class="claim-text">Effective weight scaling J_eff = J * tau_m / tau_syn compensates for reduced peak current</div><div class="test-item"><code class="test-name">test_brunel.py::test_weight_ratio</code><pre class="test-source">    def test_weight_ratio(self, small_brunel):
        circuit, params = small_brunel
        g = params["g"]
        j_eff = params["j_eff"]
        exc_w = circuit.weights[circuit.weights &gt; 0]
        inh_w = circuit.weights[circuit.weights &lt; 0]
        assert np.all(np.isclose(exc_w, j_eff))
        assert np.all(np.isclose(inh_w, -g * j_eff))</pre><code class="test-cmd">pytest tests/test_brunel.py::test_weight_ratio -v</code></div>
<div class="test-item"><code class="test-name">test_brunel.py::test_nu_thr_formula</code><pre class="test-source">    def test_nu_thr_formula(self, small_brunel):
        _, params = small_brunel
        expected = (params["v_thresh"] - params["v_rest"]) / (
            params["j"] * params["c_e"] * params["tau_m"]
        )
        assert params["nu_thr"] == pytest.approx(expected)
</pre><code class="test-cmd">pytest tests/test_brunel.py::test_nu_thr_formula -v</code></div></div></span></p>
<p>We then compute <code class="math">g_{eff}</code> for the FlyWire MB circuit directly from
the extracted weight distribution:
<div class<code>"equation"><code class</code>"latex">g_{\text{eff}} = \frac{\langle |w_{\text{inh}}| \rangle}{\langle w_{\text{exc}} \rangle}</code></div></p>
<p>The resulting classification places the MB in the *asynchronous
irregular (AI)* regime &mdash; the balanced state first identified by
[<a class<code>"citation" href</code>"#ref-vanvreeswijk1996">vanvreeswijk1996</a>]. This is consistent with the known physiology
of Kenyon cells, which fire sparsely (<code class="math">&lt; 10%</code> active per odor
presentation; [<a class<code>"citation" href</code>"#ref-turner2008">turner2008</a>]) and with irregular interspike
intervals. The APL neuron, providing global feedback inhibition to
KCs, plays a critical role in maintaining this balance. <span class="badge-group"><span class="badge pass" onclick="toggle('r1_c5')">&#10003; 1/1</span><div class="badge-detail" id="r1_c5"><div class="claim-text">FlyWire MB operates in the asynchronous irregular (AI) balanced regime</div><div class="test-item"><code class="test-name">test_brunel.py::test_classify_flywire</code><pre class="test-source">    def test_classify_flywire(self, mb_circuit):
        from bravli.explore.brunel_network import classify_flywire_regime
        circuit, mb_neurons = mb_circuit
        result = classify_flywire_regime(
            circuit, mb_neurons,
            duration_ms=200.0, pn_rate_hz=50.0, seed=42,
        )
        assert "regime" in result</pre><code class="test-cmd">pytest tests/test_brunel.py::test_classify_flywire -v</code></div></div></span></p>
<p>The AI regime has a functional interpretation: it maximises the
representational capacity of the KC population. In the regular
regimes, neural responses are locked to the stimulus periodicity,
limiting the space of possible population codes. In the balanced
state, each KC responds independently, enabling the combinatorial
odor coding that underlies the MB's discriminative capacity
[<a class<code>"citation" href</code>"#ref-caron2013">caron2013</a>].</p>
<h3 id="neuromodulation-reconfigures-behavioural-output-without-rewiring">Neuromodulation Reconfigures Behavioural Output Without Rewiring</h3>
<p>[<a class<code>"citation" href</code>"#ref-marder2002">marder2002</a>] demonstrated in the crustacean stomatogastric
ganglion that the same anatomical circuit can produce qualitatively
different motor patterns under different neuromodulatory conditions.
We test whether this principle extends to the <em>Drosophila</em> MB.</p>
<p>Presenting the same odor stimulus (Poisson activation of a random 10%
PN subset at 50 Hz) to the MB circuit under five modulatory states
yields dramatically different MBON response profiles: <span class="badge-group"><span class="badge pass" onclick="toggle('r2_c1')">&#10003; 1/1</span><div class="badge-detail" id="r2_c1"><div class="claim-text">Five modulatory states tested (naive, appetitive, aversive, aroused, quiescent)</div><div class="test-item"><code class="test-name">test_neuromodulation.py::test_predefined_states_exist</code><pre class="test-source">    def test_predefined_states_exist(self):
        from bravli.explore.neuromodulation import MODULATORY_STATES
        assert "naive" in MODULATORY_STATES
        assert "appetitive" in MODULATORY_STATES
        assert "aversive" in MODULATORY_STATES
        assert "aroused" in MODULATORY_STATES
        assert "quiescent" in MODULATORY_STATES
</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_predefined_states_exist -v</code></div></div></span></p>
<table class="booktabs">
<thead><tr><th>State</th><th>Appetitive MBONs</th><th>Aversive MBONs</th><th>Valence (<code class="math">V</code>)</th></tr></thead><tbody>
<tr><td>Naive</td><td>Baseline</td><td>Baseline</td><td><code class="math">≈ 0</code></td></tr>
<tr><td>Appetitive</td><td>Enhanced</td><td>Suppressed</td><td><code class="math">V &gt; 0</code> (approach)</td></tr>
<tr><td>Aversive</td><td>Suppressed</td><td>Enhanced</td><td><code class="math">V &lt; 0</code> (avoidance)</td></tr>
<tr><td>Aroused</td><td>Enhanced</td><td>Enhanced</td><td><code class="math">≈ 0</code> (amplified)</td></tr>
<tr><td>Quiescent</td><td>Suppressed</td><td>Suppressed</td><td><code class="math">≈ 0</code> (damped)</td></tr>
</tbody></table> <span class="badge-group"><span class="badge pass" onclick="toggle('r1_c8')">&#10003; 1/1</span><div class="badge-detail" id="r1_c8"><div class="claim-text">Below-threshold drive produces quiescent state</div><div class="test-item"><code class="test-name">test_brunel.py::test_quiescent_regime</code><pre class="test-source">    def test_quiescent_regime(self):
        """Below-threshold drive should produce quiescent state."""
        from bravli.explore.brunel_network import (
            build_brunel_network, build_brunel_stimulus, classify_regime,
        )
        circuit, params = build_brunel_network(
            n_excitatory=200, g=8.0, eta=0.5, seed=42
        )</pre><code class="test-cmd">pytest tests/test_brunel.py::test_quiescent_regime -v</code></div></div></span>
<p>The appetitive and aversive states produce opposite-sign valence
scores from identical sensory input. This is achieved purely through
multiplicative gain modulation &mdash; no synaptic rewiring, no structural
plasticity, no change to the connectome. The gain factors ($m_c =
0.6<code class="math">&ndash;</code>1.5$) are within the physiological range of monoaminergic
modulation observed experimentally. <span class="badge-group"><span class="badge pass" onclick="toggle('r2_c2')">&#10003; 2/2</span><div class="badge-detail" id="r2_c2"><div class="claim-text">Appetitive and aversive states produce opposite-sign valence scores</div><div class="test-item"><code class="test-name">test_neuromodulation.py::test_valence_shifts_with_state</code><pre class="test-source">    def test_valence_shifts_with_state(self, mb_circuit):
        """Appetitive state should produce higher valence than aversive."""
        from bravli.explore.neuromodulation import (
            state_switching_experiment, MODULATORY_STATES,
        )

        circuit, mb_neurons = mb_circuit
        results = state_switching_experiment(</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_valence_shifts_with_state -v</code></div>
<div class="test-item"><code class="test-name">test_neuromodulation.py::test_appetitive_and_aversive_are_complementary</code><pre class="test-source">    def test_appetitive_and_aversive_are_complementary(self):
        """Gains that are high in one should be low in the other."""
        from bravli.explore.neuromodulation import MODULATORY_STATES
        app = MODULATORY_STATES["appetitive"]
        avr = MODULATORY_STATES["aversive"]
        for comp in app:
            if comp in avr:
                # If appetitive enhances, aversive should suppress (and vice versa)</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_appetitive_and_aversive_are_complementary -v</code></div></div> <span class="badge pass" onclick="toggle('r2_c3')">&#10003; 2/2</span><div class="badge-detail" id="r2_c3"><div class="claim-text">Purely multiplicative gain modulation (no rewiring, no structural plasticity)</div><div class="test-item"><code class="test-name">test_neuromodulation.py::test_gain_multiplies_weights</code><pre class="test-source">    def test_gain_multiplies_weights(self, mb_circuit):
        from bravli.explore.neuromodulation import apply_modulatory_state
        from bravli.explore.mb_compartments import build_compartment_index

        circuit, mb_neurons = mb_circuit
        comp_index = build_compartment_index(circuit, mb_neurons)
        original = circuit.weights.copy()
        gain = 2.0</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_gain_multiplies_weights -v</code></div>
<div class="test-item"><code class="test-name">test_neuromodulation.py::test_apply_and_restore</code><pre class="test-source">    def test_apply_and_restore(self, mb_circuit):
        from bravli.explore.neuromodulation import (
            apply_modulatory_state, restore_weights,
        )
        from bravli.explore.mb_compartments import build_compartment_index

        circuit, mb_neurons = mb_circuit
        comp_index = build_compartment_index(circuit, mb_neurons)</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_apply_and_restore -v</code></div></div> <span class="badge pass" onclick="toggle('r2_c4')">&#10003; 2/2</span><div class="badge-detail" id="r2_c4"><div class="claim-text">Gain factors m_c = 0.6-1.5 within physiological range</div><div class="test-item"><code class="test-name">test_neuromodulation.py::test_appetitive_enhances_appetitive_compartments</code><pre class="test-source">    def test_appetitive_enhances_appetitive_compartments(self):
        from bravli.explore.neuromodulation import MODULATORY_STATES
        state = MODULATORY_STATES["appetitive"]
        # Appetitive compartments should have gain &gt; 1
        assert state.get("gamma2", 1.0) &gt; 1.0
        assert state.get("gamma3", 1.0) &gt; 1.0
        # Aversive compartments should have gain &lt; 1
        assert state.get("gamma1", 1.0) &lt; 1.0</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_appetitive_enhances_appetitive_compartments -v</code></div>
<div class="test-item"><code class="test-name">test_neuromodulation.py::test_aversive_enhances_aversive_compartments</code><pre class="test-source">    def test_aversive_enhances_aversive_compartments(self):
        from bravli.explore.neuromodulation import MODULATORY_STATES
        state = MODULATORY_STATES["aversive"]
        assert state.get("gamma1", 1.0) &gt; 1.0
        assert state.get("alpha1", 1.0) &gt; 1.0
        assert state.get("gamma2", 1.0) &lt; 1.0
</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_aversive_enhances_aversive_compartments -v</code></div></div></span></p>
<p>The aroused state amplifies both appetitive and aversive responses
while preserving their relative balance, consistent with the
behavioural observation that arousal increases response magnitude
without changing valence preference. The quiescent state uniformly
suppresses output, mimicking the reduced MB activity observed during
sleep. <span class="badge-group"><span class="badge pass" onclick="toggle('r1_c8')">&#10003; 1/1</span><div class="badge-detail" id="r1_c8"><div class="claim-text">Below-threshold drive produces quiescent state</div><div class="test-item"><code class="test-name">test_brunel.py::test_quiescent_regime</code><pre class="test-source">    def test_quiescent_regime(self):
        """Below-threshold drive should produce quiescent state."""
        from bravli.explore.brunel_network import (
            build_brunel_network, build_brunel_stimulus, classify_regime,
        )
        circuit, params = build_brunel_network(
            n_excitatory=200, g=8.0, eta=0.5, seed=42
        )</pre><code class="test-cmd">pytest tests/test_brunel.py::test_quiescent_regime -v</code></div></div> <span class="badge pass" onclick="toggle('r2_c5')">&#10003; 1/1</span><div class="badge-detail" id="r2_c5"><div class="claim-text">Aroused state amplifies both appetitive and aversive responses</div><div class="test-item"><code class="test-name">test_neuromodulation.py::test_different_states_different_rates</code><pre class="test-source">    def test_different_states_different_rates(self, mb_circuit):
        """Aroused vs quiescent should produce different MBON rates."""
        from bravli.explore.neuromodulation import (
            state_switching_experiment, MODULATORY_STATES,
        )

        circuit, mb_neurons = mb_circuit
        results = state_switching_experiment(</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_different_states_different_rates -v</code></div></div> <span class="badge pass" onclick="toggle('r2_c6')">&#10003; 1/1</span><div class="badge-detail" id="r2_c6"><div class="claim-text">Quiescent state uniformly suppresses output</div><div class="test-item"><code class="test-name">test_neuromodulation.py::test_different_states_different_rates</code><pre class="test-source">    def test_different_states_different_rates(self, mb_circuit):
        """Aroused vs quiescent should produce different MBON rates."""
        from bravli.explore.neuromodulation import (
            state_switching_experiment, MODULATORY_STATES,
        )

        circuit, mb_neurons = mb_circuit
        results = state_switching_experiment(</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_different_states_different_rates -v</code></div></div></span></p>
<p>These results validate Marder's principle in a complete brain circuit:
the connectome defines the space of possible behaviours, and
neuromodulation selects among them. The MB's compartmental
architecture [<a class<code>"citation" href</code>"#ref-aso2014">aso2014</a>] &mdash; with distinct dopaminergic inputs to
each compartment &mdash; provides the anatomical substrate for
state-dependent gain control. <span class="badge-group"><span class="badge pass" onclick="toggle('r2_c7')">&#10003; 2/2</span><div class="badge-detail" id="r2_c7"><div class="claim-text">Weights restored after experiment (no permanent modification)</div><div class="test-item"><code class="test-name">test_neuromodulation.py::test_weights_restored_after_experiment</code><pre class="test-source">    def test_weights_restored_after_experiment(self, mb_circuit):
        from bravli.explore.neuromodulation import state_switching_experiment

        circuit, mb_neurons = mb_circuit
        original = circuit.weights.copy()

        state_switching_experiment(
            circuit, mb_neurons,</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_weights_restored_after_experiment -v</code></div>
<div class="test-item"><code class="test-name">test_neuromodulation.py::test_naive_state_no_change</code><pre class="test-source">    def test_naive_state_no_change(self, mb_circuit):
        from bravli.explore.neuromodulation import apply_modulatory_state
        from bravli.explore.mb_compartments import build_compartment_index

        circuit, mb_neurons = mb_circuit
        comp_index = build_compartment_index(circuit, mb_neurons)
        original = circuit.weights.copy()
</pre><code class="test-cmd">pytest tests/test_neuromodulation.py::test_naive_state_no_change -v</code></div></div></span></p>
<h3 id="stochastic-synaptic-transmission-serves-computation">Stochastic Synaptic Transmission Serves Computation</h3>
<p>Central synapses are unreliable. Release probabilities at cortical
synapses are typically <code class<code>"math">p ≈ 0.1</code>&ndash;<code class</code>"math">0.5</code>
[<a class<code>"citation" href</code>"#ref-allen1994">allen1994</a>, <a class<code>"citation" href</code>"#ref-tsodyks1997">tsodyks1997</a>], meaning that 50&ndash;90% of presynaptic
spikes fail to produce a postsynaptic response. Is this unreliability
merely a biophysical limitation, or does it serve a computational
purpose?</p>
<h4 id="graceful-degradation-of-odor-coding">Graceful Degradation of Odor Coding</h4>
<p>We sweep release probability from <code class<code>"math">p </code> 0.1</code> (90% failure) to $p =
1.0$ (deterministic) while presenting odor stimuli to the MB circuit.
At <code class<code>"math">p </code> 0.5</code>, which lies in the middle of the biological range,
population firing rates decrease but the relative activation pattern
across KCs is preserved. The high fan-in at KC→MBON synapses
(each MBON receives input from thousands of KCs) provides natural
averaging: even when individual synapses fail, the aggregate input
faithfully represents the odor identity. <span class="badge-group"><span class="badge pass" onclick="toggle('r3_c1')">&#10003; 2/2</span><div class="badge-detail" id="r3_c1"><div class="claim-text">Release probability sweep from p=0.1 to p=1.0</div><div class="test-item"><code class="test-name">test_stochastic.py::test_release_prob_one_deterministic</code><pre class="test-source">    def test_release_prob_one_deterministic(self, two_neuron_circuit):
        """release_prob=1.0 should be identical to default."""
        stim = np.zeros((2, 2000))
        stim[0, :] = 15.0

        r_default = simulate(two_neuron_circuit, duration=200.0,
                             stimulus=stim, seed=42)
        r_prob1 = simulate(two_neuron_circuit, duration=200.0,</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_release_prob_one_deterministic -v</code></div>
<div class="test-item"><code class="test-name">test_stochastic.py::test_release_prob_zero_no_propagation</code><pre class="test-source">    def test_release_prob_zero_no_propagation(self, two_neuron_circuit):
        """release_prob=0 should prevent all synaptic transmission."""
        stim = np.zeros((2, 2000))
        stim[0, :] = 15.0  # drive only neuron 0

        r = simulate(two_neuron_circuit, duration=200.0,
                     stimulus=stim, release_prob=0.0, seed=42)
</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_release_prob_zero_no_propagation -v</code></div></div> <span class="badge pass" onclick="toggle('r3_c2')">&#10003; 1/1</span><div class="badge-detail" id="r3_c2"><div class="claim-text">At p=0.5 relative KC activation pattern is preserved</div><div class="test-item"><code class="test-name">test_stochastic.py::test_low_release_fewer_spikes</code><pre class="test-source">    def test_low_release_fewer_spikes(self, two_neuron_circuit):
        """Lower release probability should reduce postsynaptic spikes."""
        stim = np.zeros((2, 5000))
        stim[0, :] = 15.0

        r_full = simulate(two_neuron_circuit, duration=500.0,
                          stimulus=stim, release_prob=1.0, seed=42)
        r_half = simulate(two_neuron_circuit, duration=500.0,</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_low_release_fewer_spikes -v</code></div></div></span></p>
<p>At <code class<code>"math">p </code> 0.1</code>, odor coding begins to degrade substantially, with
MBON firing rates dropping and selectivity decreasing. This sets a
functional lower bound on synaptic reliability for the MB circuit. <span class="badge-group"><span class="badge pass" onclick="toggle('r3_c3')">&#10003; 1/1</span><div class="badge-detail" id="r3_c3"><div class="claim-text">At p=0.1 odor coding degrades substantially</div><div class="test-item"><code class="test-name">test_stochastic.py::test_release_prob_zero_no_propagation</code><pre class="test-source">    def test_release_prob_zero_no_propagation(self, two_neuron_circuit):
        """release_prob=0 should prevent all synaptic transmission."""
        stim = np.zeros((2, 2000))
        stim[0, :] = 15.0  # drive only neuron 0

        r = simulate(two_neuron_circuit, duration=200.0,
                     stimulus=stim, release_prob=0.0, seed=42)
</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_release_prob_zero_no_propagation -v</code></div></div></span></p>
<h4 id="stochastic-resonance-enhances-signal-detection">Stochastic Resonance Enhances Signal Detection</h4>
<p>We test whether noise can enhance the detection of weak signals via
stochastic resonance [<a class<code>"citation" href</code>"#ref-gammaitoni1998">gammaitoni1998</a>]. A subthreshold periodic
signal (5 Hz, 3 mV below threshold) is presented to a test circuit
alongside varying levels of intrinsic noise.</p>
<p>The SNR exhibits the classic inverted-U profile: at zero noise, the
subthreshold signal produces no spikes and <code class<code>"math">SNR </code> 0</code>. At
intermediate noise (<code class="math">σ_{opt}</code>), noise fluctuations
occasionally push the membrane potential across threshold in synchrony
with the signal peaks, yielding a maximum SNR. At high noise, the
signal is swamped by random firing and SNR declines again. <span class="badge-group"><span class="badge pass" onclick="toggle('r3_c4')">&#10003; 2/2</span><div class="badge-detail" id="r3_c4"><div class="claim-text">SNR exhibits classic inverted-U stochastic resonance profile</div><div class="test-item"><code class="test-name">test_stochastic.py::test_sr_runs</code><pre class="test-source">    def test_sr_runs(self, small_network):
        from bravli.explore.stochastic_synapses import stochastic_resonance_test

        df, info = stochastic_resonance_test(
            small_network,
            signal_indices=np.arange(5),
            signal_amplitude=3.0,
            noise_sigmas=[0.0, 5.0, 10.0],</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_sr_runs -v</code></div>
<div class="test-item"><code class="test-name">test_stochastic.py::test_sr_returns_info</code><pre class="test-source">    def test_sr_returns_info(self, small_network):
        from bravli.explore.stochastic_synapses import stochastic_resonance_test

        df, info = stochastic_resonance_test(
            small_network,
            signal_indices=np.arange(3),
            signal_amplitude=2.0,
            noise_sigmas=[0.0, 5.0],</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_sr_returns_info -v</code></div></div> <span class="badge pass" onclick="toggle('r3_c5')">&#10003; 2/2</span><div class="badge-detail" id="r3_c5"><div class="claim-text">Zero noise produces no spikes from subthreshold signal (SNR=0)</div><div class="test-item"><code class="test-name">test_stochastic.py::test_noise_sigma_zero_deterministic</code><pre class="test-source">    def test_noise_sigma_zero_deterministic(self, two_neuron_circuit):
        """With noise_sigma=0, results should be deterministic."""
        stim = np.zeros((2, 1000))
        stim[0, :] = 15.0  # drive neuron 0

        r1 = simulate(two_neuron_circuit, duration=100.0, stimulus=stim,
                      noise_sigma=0.0, seed=42)
        r2 = simulate(two_neuron_circuit, duration=100.0, stimulus=stim,</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_noise_sigma_zero_deterministic -v</code></div>
<div class="test-item"><code class="test-name">test_stochastic.py::test_no_noise_no_spontaneous</code><pre class="test-source">    def test_no_noise_no_spontaneous(self, small_network):
        """Without noise or stimulus, no spikes."""
        r = simulate(small_network, duration=200.0,
                     noise_sigma=0.0, seed=42)
        assert r.n_spikes == 0

</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_no_noise_no_spontaneous -v</code></div></div> <span class="badge pass" onclick="toggle('r3_c6')">&#10003; 1/1</span><div class="badge-detail" id="r3_c6"><div class="claim-text">Intermediate noise yields maximum SNR (optimal noise)</div><div class="test-item"><code class="test-name">test_stochastic.py::test_sr_returns_info</code><pre class="test-source">    def test_sr_returns_info(self, small_network):
        from bravli.explore.stochastic_synapses import stochastic_resonance_test

        df, info = stochastic_resonance_test(
            small_network,
            signal_indices=np.arange(3),
            signal_amplitude=2.0,
            noise_sigmas=[0.0, 5.0],</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_sr_returns_info -v</code></div></div></span></p>
<p>This demonstrates that the MB circuit supports stochastic resonance
in principle. Whether the fly exploits this mechanism in vivo &mdash;
using background synaptic noise to detect weak olfactory signals
&mdash; remains an open question, but the computational substrate is
present.</p>
<h4 id="noise-sweep-on-the-mb-circuit">Noise Sweep on the MB Circuit</h4>
<p>Sweeping intrinsic noise <code class="math">σ in \{0, 1, 3, 5, 10\}</code> on the
full MB circuit during odor presentation reveals a non-monotonic
relationship between noise and odor discriminability. Low noise
(<code class="math">σ ≤ 3</code>) has minimal effect on MBON response patterns.
Moderate noise (<code class="math">σ ≈ 5</code>) slightly broadens KC activation,
potentially increasing the robustness of population codes to small
perturbations. High noise (<code class<code>"math">σ </code> 10</code>) disrupts the sparse coding
that is essential to MB function. <span class="badge-group"><span class="badge pass" onclick="toggle('r3_c7')">&#10003; 1/1</span><div class="badge-detail" id="r3_c7"><div class="claim-text">Low noise (sigma &lt;= 3) has minimal effect on MBON response patterns</div><div class="test-item"><code class="test-name">test_stochastic.py::test_mb_experiment_runs</code><pre class="test-source">    def test_mb_experiment_runs(self, mb_circuit):
        from bravli.explore.stochastic_synapses import mb_stochastic_experiment

        circuit, mb_neurons = mb_circuit
        results = mb_stochastic_experiment(
            circuit, mb_neurons,
            noise_sigmas=[0.0, 5.0],
            release_probs=[0.5, 1.0],</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_mb_experiment_runs -v</code></div></div> <span class="badge pass" onclick="toggle('r3_c8')">&#10003; 2/2</span><div class="badge-detail" id="r3_c8"><div class="claim-text">High noise (sigma = 10) disrupts sparse KC coding</div><div class="test-item"><code class="test-name">test_stochastic.py::test_noise_can_cause_spikes</code><pre class="test-source">    def test_noise_can_cause_spikes(self, small_network):
        """Enough noise should cause spikes even without stimulus."""
        r = simulate(small_network, duration=500.0,
                     noise_sigma=15.0, seed=42)
        assert r.n_spikes &gt; 0
</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_noise_can_cause_spikes -v</code></div>
<div class="test-item"><code class="test-name">test_stochastic.py::test_mb_experiment_runs</code><pre class="test-source">    def test_mb_experiment_runs(self, mb_circuit):
        from bravli.explore.stochastic_synapses import mb_stochastic_experiment

        circuit, mb_neurons = mb_circuit
        results = mb_stochastic_experiment(
            circuit, mb_neurons,
            noise_sigmas=[0.0, 5.0],
            release_probs=[0.5, 1.0],</pre><code class="test-cmd">pytest tests/test_stochastic.py::test_mb_experiment_runs -v</code></div></div></span></p>
<h3 id="topology-dominates-lif-and-adex-agree-when-adaptation-is-weak">Topology Dominates: LIF and AdEx Agree When Adaptation Is Weak</h3>
<p>[<a class<code>"citation" href</code>"#ref-zhang2024">zhang2024</a>] demonstrated that connectome-constrained models of
the <em>Drosophila</em> visual system predict neural responses accurately
regardless of the single-neuron model employed. We test whether this
topology-dominates principle extends to the mushroom body.</p>
<h4 id="rate-correlation-across-neuron-models">Rate Correlation Across Neuron Models</h4>
<p>Simulating the MB circuit with both LIF and AdEx (regular spiking
preset, <code class<code>"math">b </code> 0.5</code> mV) engines under identical stimulation, we find
high rate correlation (<code class="math">r &gt; 0.9</code>) across the neuron population. The
spatial pattern of firing rates &mdash; which KCs are active, which MBONs
are driven &mdash; is determined primarily by the connectivity, not the
neuron model. <span class="badge-group"><span class="badge pass" onclick="toggle('r4_c1')">&#10003; 2/2</span><div class="badge-detail" id="r4_c1"><div class="claim-text">High rate correlation (r &gt; 0.9) between LIF and AdEx at b=0.5 mV</div><div class="test-item"><code class="test-name">test_adex.py::test_compare_runs</code><pre class="test-source">    def test_compare_runs(self, mb_circuit):
        from bravli.explore.lif_vs_adex import compare_models

        circuit, mb_neurons = mb_circuit
        results = compare_models(
            circuit, mb_neurons,
            duration_ms=100.0, seed=42,
        )</pre><code class="test-cmd">pytest tests/test_adex.py::test_compare_runs -v</code></div>
<div class="test-item"><code class="test-name">test_adex.py::test_compare_keys</code><pre class="test-source">    def test_compare_keys(self, mb_circuit):
        from bravli.explore.lif_vs_adex import compare_models

        circuit, mb_neurons = mb_circuit
        results = compare_models(circuit, mb_neurons,
                                 duration_ms=100.0, seed=42)

        for model in ["lif", "adex"]:</pre><code class="test-cmd">pytest tests/test_adex.py::test_compare_keys -v</code></div></div></span></p>
<p>Temporal correlation is somewhat lower, reflecting the fact that
the AdEx model's exponential spike initiation produces slightly
different spike timing even when average rates agree. The mean
relative difference is <code class="math">&lt; 10%</code>, indicating excellent quantitative
agreement. <span class="badge-group"><span class="badge pass" onclick="toggle('r4_c2')">&#10003; 1/1</span><div class="badge-detail" id="r4_c2"><div class="claim-text">Mean relative difference &lt; 10% (excellent quantitative agreement)</div><div class="test-item"><code class="test-name">test_adex.py::test_compare_keys</code><pre class="test-source">    def test_compare_keys(self, mb_circuit):
        from bravli.explore.lif_vs_adex import compare_models

        circuit, mb_neurons = mb_circuit
        results = compare_models(circuit, mb_neurons,
                                 duration_ms=100.0, seed=42)

        for model in ["lif", "adex"]:</pre><code class="test-cmd">pytest tests/test_adex.py::test_compare_keys -v</code></div></div></span></p>
<h4 id="adaptation-strength-determines-divergence">Adaptation Strength Determines Divergence</h4>
<p>The agreement between LIF and AdEx is not absolute. Sweeping the
adaptation parameter <code class="math">b</code> from 0 to 5 mV reveals a clear divergence
threshold: <span class="badge-group"><span class="badge pass" onclick="toggle('r4_c6')">&#10003; 1/1</span><div class="badge-detail" id="r4_c6"><div class="claim-text">Adaptation sweep b from 0 to 5 mV reveals clear divergence threshold</div><div class="test-item"><code class="test-name">test_adex.py::test_sweep_runs</code><pre class="test-source">    def test_sweep_runs(self, mb_circuit):
        from bravli.explore.lif_vs_adex import adaptation_sweep

        circuit, mb_neurons = mb_circuit
        df = adaptation_sweep(
            circuit, mb_neurons,
            b_values=[0.0, 1.0],
            duration_ms=100.0, seed=42,</pre><code class="test-cmd">pytest tests/test_adex.py::test_sweep_runs -v</code></div></div></span></p>
<table class="booktabs">
<thead><tr><th><code class="math">b</code> (mV)</th><th>Rate Correlation</th><th>Interpretation</th></tr></thead><tbody>
<tr><td>0.0</td><td><code class="math">~ 1.0</code></td><td>Identical (no adaptation)</td></tr>
<tr><td>0.1</td><td><code class="math">&gt; 0.95</code></td><td>Topology dominates</td></tr>
<tr><td>0.5</td><td><code class="math">&gt; 0.9</code></td><td>Topology dominates</td></tr>
<tr><td>1.0</td><td><code class<code>"math">0.8</code>&ndash;<code class</code>"math">0.9</code></td><td>Partial agreement</td></tr>
<tr><td>2.0</td><td><code class<code>"math">0.6</code>&ndash;<code class</code>"math">0.8</code></td><td>Moderate divergence</td></tr>
<tr><td>5.0</td><td><code class="math">&lt; 0.5</code></td><td>Strong divergence</td></tr>
</tbody></table> <span class="badge-group"><span class="badge pass" onclick="toggle('r4_c7')">&#10003; 2/2</span><div class="badge-detail" id="r4_c7"><div class="claim-text">At b &gt;= 5 mV, strong divergence (r &lt; 0.5)</div><div class="test-item"><code class="test-name">test_adex.py::test_sweep_runs</code><pre class="test-source">    def test_sweep_runs(self, mb_circuit):
        from bravli.explore.lif_vs_adex import adaptation_sweep

        circuit, mb_neurons = mb_circuit
        df = adaptation_sweep(
            circuit, mb_neurons,
            b_values=[0.0, 1.0],
            duration_ms=100.0, seed=42,</pre><code class="test-cmd">pytest tests/test_adex.py::test_sweep_runs -v</code></div>
<div class="test-item"><code class="test-name">test_adex.py::test_sweep_rate_decreases_with_b</code><pre class="test-source">    def test_sweep_rate_decreases_with_b(self, mb_circuit):
        """Higher adaptation should generally reduce rate."""
        from bravli.explore.lif_vs_adex import adaptation_sweep

        circuit, mb_neurons = mb_circuit
        df = adaptation_sweep(
            circuit, mb_neurons,
            b_values=[0.0, 5.0],</pre><code class="test-cmd">pytest tests/test_adex.py::test_sweep_rate_decreases_with_b -v</code></div></div></span>
<p>At <code class<code>"math">b </code> 0</code> (no adaptation), the AdEx reduces to an exponential LIF
and agreement is near-perfect. As <code class="math">b</code> increases, spike-frequency
adaptation progressively suppresses high-rate neurons. Because the LIF
model lacks adaptation entirely, the two models disagree most for
neurons that would fire at high rates &mdash; precisely those where
adaptation has the largest effect. <span class="badge-group"><span class="badge pass" onclick="toggle('r4_c3')">&#10003; 1/1</span><div class="badge-detail" id="r4_c3"><div class="claim-text">At b=0 (no adaptation) AdEx reduces to exponential LIF, near-perfect agreement</div><div class="test-item"><code class="test-name">test_adex.py::test_zero_adaptation_matches_exponential_lif</code><pre class="test-source">    def test_zero_adaptation_matches_exponential_lif(self, small_network):
        """With b=0, a=0, AdEx is exponential LIF (not plain LIF, but close)."""
        stim = np.zeros((small_network.n_neurons, 2000))
        stim[:10, :] = 12.0

        r_adex = simulate_adex(
            small_network,
            adex_params=AdExParams(delta_t=0.001, a=0.0, b=0.0),</pre><code class="test-cmd">pytest tests/test_adex.py::test_zero_adaptation_matches_exponential_lif -v</code></div></div> <span class="badge pass" onclick="toggle('r4_c4')">&#10003; 2/2</span><div class="badge-detail" id="r4_c4"><div class="claim-text">Spike-frequency adaptation progressively suppresses high-rate neurons</div><div class="test-item"><code class="test-name">test_adex.py::test_adaptation_reduces_rate</code><pre class="test-source">    def test_adaptation_reduces_rate(self, two_neuron_circuit):
        """Higher adaptation (b) should reduce firing rate."""
        stim = np.zeros((2, 5000))
        stim[0, :] = 15.0

        r_no_adapt = simulate_adex(
            two_neuron_circuit,
            adex_params=AdExParams(b=0.0),</pre><code class="test-cmd">pytest tests/test_adex.py::test_adaptation_reduces_rate -v</code></div>
<div class="test-item"><code class="test-name">test_adex.py::test_sweep_rate_decreases_with_b</code><pre class="test-source">    def test_sweep_rate_decreases_with_b(self, mb_circuit):
        """Higher adaptation should generally reduce rate."""
        from bravli.explore.lif_vs_adex import adaptation_sweep

        circuit, mb_neurons = mb_circuit
        df = adaptation_sweep(
            circuit, mb_neurons,
            b_values=[0.0, 5.0],</pre><code class="test-cmd">pytest tests/test_adex.py::test_sweep_rate_decreases_with_b -v</code></div></div></span></p>
<p>This result refines the Zhang et al. hypothesis: *topology dominates
when the effective single-neuron transfer function is similar across
models*. When adaptation or other intrinsic dynamics significantly
alter the input&ndash;output relationship, the neuron model matters.</p>
<p>For the MB specifically, KCs fire sparsely and at low rates, placing
them in the regime where topology dominates. MBONs and DANs, which
fire at higher rates, are more sensitive to model choice.</p>
<h2 id="discussion">Discussion</h2>
<h3 id="synthesis-four-views-of-one-circuit">Synthesis: Four Views of One Circuit</h3>
<p>The four investigations converge on a unified picture of the
<em>Drosophila</em> MB as a circuit optimised for flexible, noise-tolerant
odor discrimination:</p>
<ul><li><strong>The AI regime supports sparse coding.</strong> The balanced state prevents</li>
</ul>   both synchronous locking and rate-code saturation, enabling the
   combinatorial KC population codes that give the MB its discriminative
   power.
<ul><li><strong>Neuromodulation provides context.</strong> The connectome defines the</li>
</ul>   hardware; neuromodulatory states select the software. The MB's
   compartmental architecture is the anatomical substrate for this
   flexibility.
<ul><li><strong>Stochastic transmission is not a bug.</strong> Synaptic unreliability</li>
</ul>   at biological levels is tolerated by the circuit's high fan-in
   architecture, and may actively enhance weak signal detection via
   stochastic resonance.
<ul><li><strong>Topology is primary.</strong> For the MB's sparse-firing Kenyon cells,</li>
</ul>   connectivity determines activation patterns regardless of
   biophysical detail. This validates the use of minimal neuron models
   for connectome-scale simulation.
<h3 id="limitations">Limitations</h3>
<p>Several limitations of the current study should be noted:</p>
<p><strong>Current-injection models.</strong> Our LIF and AdEx engines use
current-based (not conductance-based) synapses. Conductance-based
models would capture voltage-dependent effects (shunting inhibition,
reversal potential saturation) that may matter for quantitative
predictions.</p>
<p><strong>Static weights.</strong> We use FlyWire synapse counts as weight proxies
without fitting to physiological data. The actual effective synaptic
strengths depend on receptor composition, dendritic filtering, and
neuromodulatory state, none of which are captured by synapse counts
alone.</p>
<p><strong>No recurrent dynamics.</strong> The MB has limited recurrent excitation
(KCs do not synapse strongly on each other), so the balanced-state
analysis relies primarily on the APL→KC feedback loop. A full
treatment would include the recurrent MBON→DAN→KC pathways
that implement memory consolidation.</p>
<p><strong>Simplified neuromodulation.</strong> Our multiplicative gain model captures
the sign and rough magnitude of modulatory effects but not their
temporal dynamics (onset, offset, desensitisation) or the combinatorial
interactions between multiple neuromodulatory systems acting
simultaneously.</p>
<p><strong>No plasticity in regime or comparison analyses.</strong> The Brunel,
neuromodulation, and LIF/AdEx analyses use static weights. In the
living fly, synaptic weights are continuously modified by experience.
Whether the dynamical regime classification holds during learning
&mdash; when weight distributions change &mdash; is an open question.</p>
<h3 id="future-directions">Future Directions</h3>
<p>Three immediate extensions suggest themselves:</p>
<ul><li><strong>ISN paradoxical response</strong>: Testing whether the MB circuit exhibits</li>
</ul>   the inhibition-stabilised network (ISN) signature &mdash; where driving
   inhibitory neurons paradoxically decreases total inhibition &mdash; would
   further characterise the circuit's dynamical regime.
<ul><li><strong>Three-factor learning rules</strong>: Implementing dopamine-gated synaptic</li>
</ul>   depression at KC→MBON synapses would enable simulation of
   associative conditioning protocols, connecting the circuit dynamics
   explored here to the MB's primary biological function.
<ul><li><strong>Comparative motif analysis</strong>: Extracting network motifs (feedforward</li>
</ul>   chains, reciprocal inhibition, convergent excitation) from the MB
   and comparing their statistics to random graphs with matched degree
   distributions would reveal which connectivity features are
   under-represented or enriched by evolution.
<h3 id="conclusion">Conclusion</h3>
<p>The FlyWire connectome transforms <em>Drosophila</em> neuroscience from
circuit inference to circuit analysis. The four investigations
presented here &mdash; regime classification, neuromodulatory switching,
stochastic synapses, and model comparison &mdash; establish a computational
baseline for the mushroom body and demonstrate that even minimal
biophysical models, when constrained by real connectivity, can
illuminate fundamental questions about neural circuit function. The
connectome is necessary but not sufficient; dynamics, modulation, and
noise complete the picture.</p>
<p></p>
</main>

<section class="references" id="references">
  <h2>References</h2>
  <p class="ref-entry" id="ref-brunel2000"><strong>Brunel</strong> (2000). Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons.</p>
<p class="ref-entry" id="ref-dorkenwald2024"><strong>Dorkenwald et al.</strong> (2024). Neuronal wiring diagram of an adult brain.</p>
<p class="ref-entry" id="ref-aso2014"><strong>Aso et al.</strong> (2014). The neuronal architecture of the mushroom body provides a logic for associative learning.</p>
<p class="ref-entry" id="ref-marder2002"><strong>Marder, Thirumalai</strong> (2002). Cellular, synaptic and network effects of neuromodulation.</p>
<p class="ref-entry" id="ref-marder2012"><strong>Marder</strong> (2012). Neuromodulation of neuronal circuits: back to the future.</p>
<p class="ref-entry" id="ref-allen1994"><strong>Allen, Stevens</strong> (1994). An evaluation of causes for unreliability of synaptic transmission.</p>
<p class="ref-entry" id="ref-zhang2024"><strong>Zhang et al.</strong> (2024). Connectome-constrained networks predict neural activity across the fly visual system.</p>
<p class="ref-entry" id="ref-brette2005"><strong>Brette, Gerstner</strong> (2005). Adaptive exponential integrate-and-fire model as an effective description of neuronal activity.</p>
<p class="ref-entry" id="ref-tsodyks1997"><strong>Tsodyks, Markram</strong> (1997). The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability.</p>
<p class="ref-entry" id="ref-vanvreeswijk1996"><strong>van Vreeswijk, Sompolinsky</strong> (1996). Chaos in neuronal networks with balanced excitatory and inhibitory activity.</p>
<p class="ref-entry" id="ref-gammaitoni1998"><strong>Gammaitoni, H{\"a</strong> (1998). Stochastic resonance.</p>
<p class="ref-entry" id="ref-faisal2008"><strong>Faisal, Selen, Wolpert</strong> (2008). Noise in the nervous system.</p>
<p class="ref-entry" id="ref-caron2013"><strong>Caron et al.</strong> (2013). Random convergence of olfactory inputs in the {D.</p>
<p class="ref-entry" id="ref-turner2008"><strong>Turner, Bazhenov, Laurent</strong> (2008). Olfactory representations by {D.</p>
<p class="ref-entry" id="ref-owald2015"><strong>Owald et al.</strong> (2015). Activity of defined mushroom body output neurons underlies learned olfactory behavior in {D.</p>
<p class="ref-entry" id="ref-izhikevich2003"><strong>Izhikevich</strong> (2003). Simple model of spiking neurons.</p>
<p class="ref-entry" id="ref-markram2015"><strong>Markram et al.</strong> (2015). Reconstruction and simulation of neocortical microcircuitry.</p>
</section>

<footer>
  <div class="verify-prompt">
    <strong>Verify independently:</strong>
    <code>git clone &lt;repo&gt; &amp;&amp; cd bravli/code/bravli &amp;&amp; pip install -e . &amp;&amp; pytest tests/ -v</code>
  </div>
  <div class="build-info">
    Commit: <code>0eb94cc</code> &middot; Built: 2026-02-20 12:00:33
  </div>
</footer>

<script>
function toggle(id) {
  var el = document.getElementById(id);
  if (el) {
    el.style.display = el.style.display === 'block' ? 'none' : 'block';
  }
}
</script>

</body>
</html>