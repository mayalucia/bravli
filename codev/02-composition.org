#+title: Lesson 02 — Composition
#+subtitle: What lives inside a neuropil: cell types, neurotransmitters, and the questions that remain
#+author: bravli Collaboration
#+property: header-args:python :mkdirp yes
#+startup: showall

* What This Lesson Teaches

At the Blue Brain Project, computing the composition of a brain region was /the/ hard
problem. The pipeline took Nissl stain intensity volumes, in-situ hybridization (ISH)
gene marker volumes, and sparse literature measurements, then fitted a constrained
optimization to produce voxel-level cell density estimates. Months of work went into
getting the cerebellum right. The thalamus needed manual corrections. The whole-brain
generalization was never completed.

For the fly brain, the composition problem is solved. The FlyWire connectome gives us
every neuron, individually identified, with:
- A =cell_type= assignment (8,453 types)
- A =super_class= (central, optic, sensory, etc.)
- A =cell_class= and =cell_sub_class= for finer grouping
- A predicted neurotransmitter (=top_nt=) with confidence score
- A hemisphere assignment (=side=)

So why do we need a composition module at all? Because /raw data is not understanding/.
Having 139,255 rows in a table is not the same as knowing that the mushroom body Kenyon
cells are predominantly cholinergic, or that optic lobe neurons use GABA at twice the
rate of central brain neurons. Composition analysis transforms a flat table into
structured knowledge: counts, proportions, distributions, comparisons.

This module provides pure functions that take a DataFrame and return summary statistics.
Each function is decorated with =@evaluate_datasets= so it can accept either raw data
or =Dataset= objects. The functions are deliberately simple — the complexity lives in
the questions you ask, not in the code that answers them.

** Learning Objectives

- [ ] Compute neuron counts per super_class and cell_class
- [ ] Compute cell type distributions within a class
- [ ] Compute neurotransmitter profiles (absolute and proportional)
- [ ] Compare composition across anatomical divisions
- [ ] Understand why simple functions + =@evaluate_datasets= beat complex pipelines

** File Map

| File                               | Role                                     |
|------------------------------------+------------------------------------------|
| =bravli/composition/__init__.py=  | Subpackage exports                       |
| =bravli/composition/composition.py= | Composition analysis functions          |
| =tests/test_composition.py=       | Tests with synthetic data                |

* Architecture

#+begin_example
     FlyWire annotation DataFrame
     (root_id, super_class, cell_class, cell_type, top_nt, ...)
                    │
                    ▼
     ┌── composition.py ────────────────────────────┐
     │                                               │
     │  count_by(df, column)         → Series        │
     │  cell_type_distribution(df)   → DataFrame     │
     │  neurotransmitter_profile(df) → DataFrame     │
     │  compare_divisions(df, col)   → DataFrame     │
     │                                               │
     │  All @evaluate_datasets — accept Dataset or   │
     │  raw DataFrame transparently                  │
     └───────────────────────────────────────────────┘
#+end_example

The design: every function takes a DataFrame (or a subset of one) and returns a
summary. Filtering — "give me only central brain neurons" — happens /before/ calling
these functions, using the parcellation module's query methods. This separation keeps
composition functions generic and reusable.

* Implementation

** Composition subpackage init

#+begin_src python :tangle ../bravli/composition/__init__.py
"""composition — Cell type distributions and neurotransmitter profiles.

Pure functions that summarize the cellular composition of brain regions.
All functions accept either raw DataFrames or Dataset objects via the
@evaluate_datasets decorator.
"""

from .composition import (
    count_by,
    cell_type_distribution,
    neurotransmitter_profile,
    compare_divisions,
    top_types,
)
#+end_src

** Composition functions

Each function does one thing. The naming convention: the function name describes the
/output/ (what you get), not the /input/ (what you give). You give it a DataFrame of
neurons; you get back a structured summary.

#+begin_src python :tangle ../bravli/composition/composition.py
"""Composition analysis: cell type counts, neurotransmitter profiles.

Every function here is a pure transformation: DataFrame in, summary out.
The @evaluate_datasets decorator allows passing Dataset objects directly.

Heritage: these functions replace the complex atlas-densities pipeline
from BBP. There, composition was /inferred/ from sparse ISH data via
constrained optimization. Here, it is /counted/ from complete annotations.
The shift from inference to counting changes everything — except the
questions we want to answer.
"""

import pandas as pd
import numpy as np

from bravli.bench.dataset import evaluate_datasets


@evaluate_datasets
def count_by(annotations, column):
    """Count neurons grouped by a column.

    Parameters
    ----------
    annotations : pd.DataFrame
        Neuron annotation table.
    column : str
        Column to group by (e.g., 'super_class', 'cell_class', 'cell_type').

    Returns
    -------
    pd.Series
        Neuron counts indexed by the grouping column, sorted descending.
    """
    return (annotations
            .groupby(column)
            .size()
            .sort_values(ascending=False)
            .rename("neuron_count"))


@evaluate_datasets
def cell_type_distribution(annotations, grouping="cell_type", normalize=False):
    """Distribution of cell types within an annotation set.

    Parameters
    ----------
    annotations : pd.DataFrame
        Neuron annotations (typically a subset for one region/class).
    grouping : str
        Column to use for cell type identity.
    normalize : bool
        If True, return proportions instead of counts.

    Returns
    -------
    pd.DataFrame
        Columns: neuron_count (and proportion if normalize=True).
    """
    counts = count_by.__wrapped__(annotations, grouping)
    result = counts.to_frame()
    if normalize:
        result["proportion"] = result["neuron_count"] / result["neuron_count"].sum()
    return result


@evaluate_datasets
def neurotransmitter_profile(annotations, nt_column="top_nt",
                             conf_column="top_nt_conf", min_confidence=0.0):
    """Neurotransmitter composition of a set of neurons.

    Parameters
    ----------
    annotations : pd.DataFrame
        Neuron annotations.
    nt_column : str
        Column with neurotransmitter prediction.
    conf_column : str
        Column with prediction confidence.
    min_confidence : float
        Minimum confidence to include a prediction (0.0 = include all).

    Returns
    -------
    pd.DataFrame
        Columns: neuron_count, proportion, mean_confidence.
    """
    df = annotations
    if conf_column in df.columns and min_confidence > 0:
        df = df[df[conf_column] >= min_confidence]

    counts = df.groupby(nt_column).size().rename("neuron_count")
    total = counts.sum()
    result = counts.to_frame()
    result["proportion"] = result["neuron_count"] / total

    if conf_column in df.columns:
        mean_conf = df.groupby(nt_column)[conf_column].mean()
        result["mean_confidence"] = mean_conf

    return result.sort_values("neuron_count", ascending=False)


@evaluate_datasets
def compare_divisions(annotations, column, division_column="super_class"):
    """Compare a property across anatomical divisions.

    Parameters
    ----------
    annotations : pd.DataFrame
        Full neuron annotation table.
    column : str
        Property to compare (e.g., 'top_nt', 'cell_class').
    division_column : str
        Column defining the divisions (default: 'super_class').

    Returns
    -------
    pd.DataFrame
        Cross-tabulation: divisions as columns, property values as rows.
        Values are proportions within each division.
    """
    ct = pd.crosstab(
        annotations[column],
        annotations[division_column],
        normalize="columns",
    )
    return ct


@evaluate_datasets
def top_types(annotations, n=10, grouping="cell_type"):
    """The N most abundant cell types.

    Parameters
    ----------
    annotations : pd.DataFrame
        Neuron annotations.
    n : int
        How many types to return.
    grouping : str
        Column defining cell type identity.

    Returns
    -------
    pd.DataFrame
        Top N types with neuron_count and proportion.
    """
    dist = cell_type_distribution.__wrapped__(annotations, grouping=grouping,
                                              normalize=True)
    return dist.head(n)
#+end_src

** Tests

#+begin_src python :tangle ../tests/test_composition.py
"""Tests for composition analysis functions."""

import pandas as pd
import pytest

from bravli.composition.composition import (
    count_by,
    cell_type_distribution,
    neurotransmitter_profile,
    compare_divisions,
    top_types,
)
from bravli.bench.dataset import Dataset


@pytest.fixture
def neurons():
    """Synthetic neuron annotation table."""
    return pd.DataFrame({
        "root_id": range(1, 11),
        "super_class": ["central"] * 6 + ["optic"] * 4,
        "cell_class": ["KC", "KC", "KC", "MBON", "MBON", "CX",
                        "Mi", "Mi", "Tm", "T4"],
        "cell_type": ["KC_a", "KC_a", "KC_b", "MBON_a", "MBON_b", "PFN",
                       "Mi1", "Mi1", "Tm1", "T4a"],
        "top_nt": ["acetylcholine"] * 3 + ["glutamate"] * 2 +
                  ["GABA"] + ["acetylcholine"] * 2 + ["GABA"] * 2,
        "top_nt_conf": [0.95, 0.90, 0.85, 0.92, 0.88, 0.91,
                        0.93, 0.87, 0.90, 0.86],
    })


class TestCountBy:
    def test_by_super_class(self, neurons):
        result = count_by(neurons, "super_class")
        assert result["central"] == 6
        assert result["optic"] == 4

    def test_by_cell_type(self, neurons):
        result = count_by(neurons, "cell_type")
        assert result["KC_a"] == 2

    def test_accepts_dataset(self, neurons):
        ds = Dataset(name="n", ftype="csv").with_data(neurons)
        result = count_by(ds, "super_class")
        assert result["central"] == 6


class TestCellTypeDistribution:
    def test_counts(self, neurons):
        dist = cell_type_distribution(neurons)
        assert "neuron_count" in dist.columns
        assert dist.loc["KC_a", "neuron_count"] == 2

    def test_normalized(self, neurons):
        dist = cell_type_distribution(neurons, normalize=True)
        assert "proportion" in dist.columns
        assert abs(dist["proportion"].sum() - 1.0) < 1e-10


class TestNeurotransmitterProfile:
    def test_profile(self, neurons):
        nt = neurotransmitter_profile(neurons)
        assert "acetylcholine" in nt.index
        assert nt.loc["acetylcholine", "neuron_count"] == 5
        assert "proportion" in nt.columns

    def test_confidence_filter(self, neurons):
        nt = neurotransmitter_profile(neurons, min_confidence=0.90)
        # Only neurons with conf >= 0.90 included
        total = nt["neuron_count"].sum()
        assert total < len(neurons)

    def test_mean_confidence(self, neurons):
        nt = neurotransmitter_profile(neurons)
        assert "mean_confidence" in nt.columns


class TestCompareDivisions:
    def test_crosstab(self, neurons):
        ct = compare_divisions(neurons, "top_nt")
        assert "central" in ct.columns
        assert "optic" in ct.columns
        # Each column sums to ~1.0 (proportions)
        for col in ct.columns:
            assert abs(ct[col].sum() - 1.0) < 1e-10


class TestTopTypes:
    def test_top_n(self, neurons):
        top = top_types(neurons, n=3)
        assert len(top) == 3
        assert top.index[0] == "KC_a"  # most abundant
#+end_src

* Key Design Decisions

| Decision                            | Rationale                                                             |
|-------------------------------------+-----------------------------------------------------------------------|
| Pure functions, not methods          | Composable, testable, no hidden state. Filter before, summarize after.|
| =@evaluate_datasets= on every function | Uniform interface: raw data or Dataset, your choice.                |
| =__wrapped__= for internal calls    | When one composition function calls another, skip double-unwrapping.  |
| Proportions optional (=normalize=)  | Counts are the ground truth. Proportions are derived. Keep both.      |
| No neuropil-specific logic here      | Neuropil filtering belongs in parcellation. Composition is generic.   |

* Testing

#+begin_src bash :tangle no
pytest tests/test_composition.py -v
#+end_src

* Exercises for the Reader

1. *Entropy of cell type distributions*: Compute the Shannon entropy of cell type
   distributions for central brain vs optic lobe. Which is more diverse?

2. *Confidence-gated profiles*: How does the neurotransmitter profile change as you
   increase the =min_confidence= threshold from 0.5 to 0.9? At what threshold do
   rare neurotransmitters disappear?

3. *Bilateral comparison*: Filter annotations by =side == "left"= vs =side == "right"=
   and compare cell type distributions. Use =compare_divisions= with =division_column="side"=.

* Requirements for Agents                                        :noexport:

#+begin_src yaml :tangle no
lesson: 02-composition
tag: lesson/02-composition
files_created:
  - bravli/composition/__init__.py
  - bravli/composition/composition.py
  - tests/test_composition.py
verification:
  - "python -c 'from bravli.composition import count_by, neurotransmitter_profile' succeeds"
  - "pytest tests/test_composition.py -v — all tests pass"
next_lesson: 03-factology
#+end_src

* Local Variables                                                :noexport:

# Local Variables:
# org-confirm-babel-evaluate: nil
# End:
